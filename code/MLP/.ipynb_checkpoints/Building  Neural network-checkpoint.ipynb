{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "chinese-hundred",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "inputs = [[1, 2, 3, 2.5],\n",
    "        [2.0, 5.0, -1.0, 2.0],\n",
    "         [-1.5, 2.7, 3.3, -0.8]]\n",
    "weights = [[0.2, 0.8, -0.5, 1],\n",
    "            [0.5, -0.91, 0.26, -0.5],\n",
    "            [-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2,3,0.5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "geological-chicago",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.8  ,  1.21 ,  2.385],\n",
       "       [ 8.9  , -1.81 ,  0.2  ],\n",
       "       [ 1.41 ,  1.051,  0.026]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1_out = np.dot(inputs,np.array(weights).T)+biases\n",
    "layer1_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "suspended-lobby",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "weights2 = [[0.1, -0.14, 0.5],\n",
    "            [-0.5, 0.12, -0.33],\n",
    "            [-0.44, 0.73, -0.13]]\n",
    "biases2 = [-1, 2, -0.5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "unable-connecticut",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5031 , -1.04185, -2.03875],\n",
       "       [ 0.2434 , -2.7332 , -5.7633 ],\n",
       "       [-0.99314,  1.41254, -0.35655]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights2 = np.array(weights2)\n",
    "\n",
    "layer2_out = np.dot(layer1_out, weights2.T) + biases2\n",
    "layer2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "addressed-rotation",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "class Layer_Dense:\n",
    "    \n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        \"\"\"initializes weights and biases\"\"\"\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        \n",
    "    def backward(self, dvalues):\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        self.inputs = np.dot(dvalues, self.weights.T)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "incredible-participant",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = spiral_data(samples=100, classes= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "loving-stress",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-7.96105637e-05, -1.97224600e-05,  6.68923973e-05],\n",
       "       [-1.69826106e-04, -2.99537171e-05,  1.44244557e-04],\n",
       "       [ 5.78901014e-05, -2.57421094e-04, -8.33785640e-05],\n",
       "       [-3.09068303e-04, -8.70711657e-05,  2.58350601e-04]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense1 = Layer_Dense(2, 3)\n",
    "\n",
    "dense1.forward(X)\n",
    "dense1.output[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "elder-packaging",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "class Acti_Relu:\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0,inputs)\n",
    "        \n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = dvalues.copy()\n",
    "        self.dinputs[self.inputs <= 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "hispanic-watch",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 6.68923973e-05]\n",
      " [0.00000000e+00 0.00000000e+00 1.44244557e-04]\n",
      " [5.78901014e-05 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.58350601e-04]]\n"
     ]
    }
   ],
   "source": [
    "activation1 = Acti_Relu()\n",
    "\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "print(activation1.output[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "sealed-pendant",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "exp_values = np.exp(inputs)\n",
    "\n",
    "probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "proof-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Acti_SoftMax:\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs,\n",
    "                                           axis=1,\n",
    "                                           keepdims=True))\n",
    "        probabilities = exp_values / np.sum(exp_values,\n",
    "                                           axis=1,\n",
    "                                           keepdims=True)\n",
    "        self.output = probabilities\n",
    "        \n",
    "    def backward(self, dvalues):\n",
    "        \n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "        \n",
    "        for i, (single_output, single_dvalues) in \\\n",
    "                            enumerate(zip(self.output, dvalues)):\n",
    "            single_output = single_output.reshape(-1,1)\n",
    "            \n",
    "            jacobian_matrix = np.diagflat(single_output) - \\\n",
    "                                np.dot(single_output, single_output.T)\n",
    "            self.dinputs[i] = np.dot(jacobian_matrix, single_dvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "horizontal-wireless",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09003057 0.24472847 0.66524096]]\n"
     ]
    }
   ],
   "source": [
    "softmax = Acti_SoftMax()\n",
    "\n",
    "softmax.forward([[1, 2, 3]])\n",
    "print(softmax.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "continuous-juvenile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333333 0.33333333 0.33333333]\n",
      " [0.33333349 0.33333319 0.33333332]\n",
      " [0.33333367 0.33333303 0.3333333 ]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.33333395 0.33333278 0.33333327]]\n"
     ]
    }
   ],
   "source": [
    "dense1 = Layer_Dense(2, 3)\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "\n",
    "activation1 = Acti_Relu()\n",
    "activation2 = Acti_SoftMax()\n",
    "\n",
    "dense1.forward(X)\n",
    "activation1.forward(dense1.output)\n",
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "print(activation2.output[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "comparative-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_out = np.array([[0.7, 0.1, 0.2],\n",
    "              [0.5, 0.1, 0.4],\n",
    "              [0.02, 0.9, 0.08]])\n",
    "class_targets = np.array([[1, 0, 0], [0,1,0], [0, 1, 0]]) # index of write\n",
    "\n",
    "neg_log = -np.log(softmax_out[range(len(softmax_out)), class_targets])\n",
    "average_loss = np.mean(neg_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "southeast-wrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9215401841968681\n"
     ]
    }
   ],
   "source": [
    "if len(class_targets.shape)==1:\n",
    "    correct_confidence = softmax_out[\n",
    "                            range(len(softmax_out)),\n",
    "                            class_targets]\n",
    "elif len(class_targets.shape) == 2:\n",
    "    correct_confidence = np.sum(softmax_out * class_targets, axis=1)\n",
    "    \n",
    "neg_log = -np.log(correct_confidence)\n",
    "\n",
    "average_loss = np.mean(neg_log)\n",
    "\n",
    "print(average_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cubic-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def calculate(self, output, y):\n",
    "        sample_losses = self.forward(output, y)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "worst-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategoCrossentropy(Loss): # inheriting LOSS class\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        \n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1-1e-7) # to prevent overflow and diveding by 0\n",
    "        \n",
    "        if len(class_targets.shape)==1:\n",
    "            correct_confidence = softmax_out[\n",
    "                                    range(len(softmax_out)),\n",
    "                                    class_targets]\n",
    "        elif len(class_targets.shape) == 2:\n",
    "            correct_confidence = np.sum(softmax_out * class_targets, axis=1)\n",
    "\n",
    "        neg_log = -np.log(correct_confidence)\n",
    "\n",
    "        return neg_log\n",
    "    \n",
    "    def backward(self, dvalues, y_true):\n",
    "        \n",
    "        samples=len(dvalues)\n",
    "        \n",
    "        labels = len(dvalues[0])\n",
    "        \n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "            \n",
    "        self.dinputs = -y_true / dvalues\n",
    "        \n",
    "        self.dinputs = self.dinputs / samples\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "public-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.activation = Acti_SoftMax()\n",
    "        self.loss = Loss_CategoCrossentropy()\n",
    "        \n",
    "    def forward(self, inputs, y_true):\n",
    "        self.activation.forward(inputs)\n",
    "        \n",
    "        self.output = self.activation.output\n",
    "        \n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "    \n",
    "    def backward(self, dvalues, y_true):\n",
    "        \n",
    "        samples = len(dvalues)\n",
    "        \n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "            \n",
    "        self.dinputs = dvalues.copy()\n",
    "        \n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "        \n",
    "        self.dinputs = self.dinputs / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "diverse-performer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9215401841968681"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = Loss_CategoCrossentropy()\n",
    "loss = loss_func.calculate(softmax_out, class_targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "liable-boxing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333333 0.33333333 0.33333333]\n",
      " [0.33333456 0.33333318 0.33333226]\n",
      " [0.33333576 0.33333303 0.33333121]\n",
      " [0.33333652 0.33333293 0.33333055]\n",
      " [0.33333825 0.33333271 0.33332904]]\n",
      "0.9215401841968681\n"
     ]
    }
   ],
   "source": [
    "dense1 = Layer_Dense(2, 3)\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "\n",
    "activation1 = Acti_Relu()\n",
    "activation2 = Acti_SoftMax()\n",
    "\n",
    "loss_func = Loss_CategoCrossentropy()\n",
    "\n",
    "dense1.forward(X)\n",
    "activation1.forward(dense1.output)\n",
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "print(activation2.output[:5])\n",
    "\n",
    "loss = loss_func.calculate(activation2.output, y)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "regional-change",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(softmax_out, axis=1)\n",
    "\n",
    "if len(class_targets.shape) == 2:\n",
    "    class_targets = np.argmax(class_targets, axis=1)\n",
    "    \n",
    "accuracy = np.mean(predictions==class_targets)\n",
    "\n",
    "print(\"acc\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "collective-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnfs.datasets import vertical_data\n",
    "\n",
    "X, y =vertical_data(samples=100, classes=3)\n",
    "\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "activation1 = Acti_Relu()\n",
    "\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "activation2 = Acti_SoftMax()\n",
    "\n",
    "loss_func = Loss_CategoCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "later-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.0, -2.0, 3.0])\n",
    "w = np.array([-3.0, -1.0, 2.0])\n",
    "b = 1.0\n",
    "\n",
    "z = np.dot(x,w.T)+b\n",
    "y =(z,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "requested-regard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0 1.0 1.0 1.0\n",
      "-3.0 1.0 -1.0 -2.0 2.0 3.0\n"
     ]
    }
   ],
   "source": [
    "dvalue = 1.0\n",
    "# Derivative of ReLU\n",
    "drelu_dz = dvalue *(1.0 if z > 0 else 0.0)\n",
    "print(drelu_dz)\n",
    "# Partial derivative of sum\n",
    "dsum_dxw0 = 1 \n",
    "drelu_dxw0 = drelu_dz * dsum_dxw0\n",
    "dsum_dxw1 = 1 \n",
    "drelu_dxw1 = drelu_dz * dsum_dxw1\n",
    "dsum_dxw2 = 1 \n",
    "drelu_dxw2 = drelu_dz * dsum_dxw2\n",
    "dsum_dxb = 1 \n",
    "drelu_db = drelu_dz * dsum_dxb\n",
    "print(drelu_dxw0, drelu_dxw1, drelu_dxw2, drelu_dxb)\n",
    "# Partial derivative of multiplication\n",
    "dmul_dx0 = w[0]\n",
    "drelu_dx0 = drelu_dxw0 * dmul_dx0\n",
    "dmul_dx1 = w[1]\n",
    "drelu_dx1 = drelu_dxw1 * dmul_dx1\n",
    "dmul_dx2 = w[2]\n",
    "drelu_dx2 = drelu_dxw2 * dmul_dx2\n",
    "\n",
    "dmul_dw0 = x[0]\n",
    "drelu_dw0 = drelu_dxw0 * dmul_dw0\n",
    "dmul_dw1 = x[1]\n",
    "drelu_dw1 = drelu_dxw1 * dmul_dw1\n",
    "dmul_dw2 = x[2]\n",
    "drelu_dw2 = drelu_dxw2 * dmul_dw2\n",
    "\n",
    "print(drelu_dx0, drelu_dw0, drelu_dx1, drelu_dw1, drelu_dx2, drelu_dw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "distributed-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = [drelu_dx0, drelu_dx1, drelu_dx2]\n",
    "dw = [drelu_dw0, drelu_dw1, drelu_dw2]\n",
    "db = drelu_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "handled-cable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.001, -0.998,  1.997])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w += (np.multiply(-0.001, dw))\n",
    "b += -0.001 * db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "virgin-chemistry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.985, 0)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.dot(x,w.T)+b\n",
    "y =(z,0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "indian-judgment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44, -0.38, -0.07,  1.37],\n",
       "       [ 0.88, -0.76, -0.14,  2.74],\n",
       "       [ 1.32, -1.14, -0.21,  4.11]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvalues = np.array([[1.,1.,1.],\n",
    "                   [2.,2.,2.],\n",
    "                   [3.,3.,3.]])\n",
    "\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91, 0.26, -0.5],\n",
    "                    [-0.26, -0.27, 0.17, 0.87]]).T\n",
    "\n",
    "dinputs = np.dot(dvalues, weights.T)\n",
    "dinputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "intended-malawi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0.5],\n",
       "       [20.1, 20.1, 20.1],\n",
       "       [10.9, 10.9, 10.9],\n",
       "       [ 4.1,  4.1,  4.1]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvalues = np.array([[1.,1.,1.],\n",
    "                   [2.,2.,2.],\n",
    "                   [3.,3.,3.]])\n",
    "\n",
    "inputs = np.array([[1, 2, 3, 2.5],\n",
    "                    [2.0, 5.0, -1.0, 2.0],\n",
    "                     [-1.5, 2.7, 3.3, -0.8]])\n",
    "dweights = np.dot(inputs.T, dvalues)\n",
    "dweights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "adaptive-april",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 6., 6.]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvalues = np.array([[1.,1.,1.],\n",
    "                   [2.,2.,2.],\n",
    "                   [3.,3.,3.]])\n",
    "\n",
    "biases = [2,3,0.5]\n",
    "\n",
    "dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "dbiases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "narrative-digit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  0,  0],\n",
       "       [ 5,  0,  0,  8],\n",
       "       [ 0, 10, 11,  0]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.array([[1,2,-3,-4],\n",
    "             [2, -7, -1, 3],\n",
    "             [-1, 2, 5, -1]])\n",
    "\n",
    "dvalues = np.array([[1,2,3,4,],\n",
    "                   [5,6,7,8],\n",
    "                   [9,10,11,12]])\n",
    "\n",
    "drelu = dvalues.copy()\n",
    "drelu[z<=0]=0\n",
    "\n",
    "drelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "nasty-genetics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.1       ,  0.03333333,  0.06666667],\n",
       "        [ 0.03333333, -0.16666667,  0.13333333],\n",
       "        [ 0.00666667, -0.03333333,  0.02666667]]),\n",
       " array([[-0.09999999,  0.03333334,  0.06666667],\n",
       "        [ 0.03333334, -0.16666667,  0.13333334],\n",
       "        [ 0.00666667, -0.03333333,  0.02666667]]))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnfs.init()\n",
    "softmax_out = np.array([[0.7, 0.1, 0.2],\n",
    "                      [0.1, 0.5, 0.4],\n",
    "                      [0.02, 0.9, 0.08]])\n",
    "class_targets = np.array([0, 1, 1])\n",
    "\n",
    "softmax_loss = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "softmax_loss.backward(softmax_out, class_targets)\n",
    "dvalues1 = softmax_loss.dinputs\n",
    "\n",
    "activation = Acti_SoftMax()\n",
    "activation.output = softmax_out\n",
    "\n",
    "loss = Loss_CategoCrossentropy()\n",
    "loss.backward(softmax_out, class_targets)\n",
    "activation.backward(loss.dinputs)\n",
    "\n",
    "dvalues2 = activation.dinputs\n",
    "\n",
    "dvalues1, dvalues2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-awareness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
